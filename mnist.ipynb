{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Phân lớp ảnh với bộ dữ liệu MNIST\n",
    "\n",
    "\n",
    "## 1.1. Tại sao dùng mạng nơron tích chập\n",
    "Đặc điểm cấu trúc chính của các mạng thông thường là tất cả các nơron được nối với nhau. Thí dụ, khi ta có ảnh xám với kích thước 28 nhân 28 pixel, ta sẽ có 784 (28 x 28 x 1) nơron vào 1 lớp và trong trường hợp này có thể quản lý được. Tuy nhiên hầu hết các ảnh có số pixel nhiều hơn vậy và đồng thời cũng không phải là ảnh xám. Do đó, giả sử ta có tập ảnh mầu dạng 4K Ultra HD, ta sẽ có 26,542,080 (4096 x 2160 x 3) nơron khác nhau được kết nối với nhau ở lớp đầu tiên và rõ ràng là không quản lý được. Do đó ta có thể nói rằng các mạng thông thường không có khả năng mở rộng cho việc phân lớp ảnh. Tuy nhiên, đối với ảnh, dường như chỉ có 1 chút ít tương quan hay quan hệ giữa 2 pixel riêng biệt nếu chúng không gần với nhau. Điều này dẫn tới ý tượng của lớp tích chập và lớp Pooling.\n",
    "\n",
    "## 1.2. Các lớp trong CNN\n",
    "Chúng ta có thể sử dụng nhiều lớp khác nhau trong một mạng nơron tích chập. Tuy nhiên, các lớp convolution, pooling, và fully connect là các lớp quan trọng nhất. Do đó ta sẽ xem qua các lớp này trước khi thể hiện chúng.\n",
    "\n",
    "### Lớp tích chập\n",
    "Lớp tích chập là lớp đầu tiên ta dùng để trích các đặc trưng từ ảnh trong bộ dữ liệu của ta. Do thực tế là các pixel chỉ liên quan tới các pixel kề và gần với nó, tích chập cho phép ta bảo tồn quan hệ giữa các phần khác nhau của ảnh. Tích chập về cơ bản là phép lọc ảnh với bộ lọc có số pixel nhỏ hơn để giảm kích thước của ảnh mà không mất các quan hệ giữa các pixel. Khi ta áp dụng tích chập tới ảnh 5x5 sử dụng bộ lọc 3x3 với bước 1x1 (dịch 1 pixel trong mỗi bước). Cuối cùng ta sẽ có đầu ra 3x3 (giảm 64% độ phức tạp).\n",
    "<img src=\"files/convolutionlayer.png\">\n",
    "\n",
    "### Lớp Pooling\n",
    "Khi xây dựng CNN, ta thường bổ sung các lớp pooling sau mỗi lớp tích chập để giảm kích thước không gian của thể hiện để giảm số tham số mà nghĩa là giảm độ phức tạp tính toán. Thêm nữa, các lớp pooling cũng giúp giảm vấn đề quá khớp (overfitting). Về cơ bản ta chọn một kích thước pooling để giảm số các tham số bằng cách chọn các giá trị lớn nhất, trung bình, hay tổng của các pixel này. Max Pooling, một trong những kỹ thuật pooling phổ biến nhất, có thể được thể hiện như sau:\n",
    "<img src=\"files/poolinglayer.png\">\n",
    "\n",
    "### Tập các lớp Fully Connected\n",
    "Mạng kết nối đầy đủ là mạng thông thường của ta, ở đó mỗi tham số được liên kết tới các khác để xác định quan hệ và ảnh hưởng thật của mỗi tham số tới nhãn. Từ khi độ phức tạp không gian - thời gian của ta đã được giảm đáng kể nhờ các lớp tích chập và pooling, ta có thể xây dựng một mạng kết nối đầy đủ ở cuối của mạng phân lớp ảnh của ta. Tập các lớp kết nối đầy đủ như trong hình sau:\n",
    "<img src=\"files/fullyconnectedlayer.png\">\n",
    "\n",
    "Tới đây ta đã có một số ý tưởng về các lớp riêng rẽ, ta có thể nhìn qua một mạng nơron tích chập hoàn chỉnh.\n",
    "<img src=\"files/cnnexample.jpeg\">\n",
    "\n",
    "Ta đã có ý tưởng về mạng nơron tích chập và như vậy có thể xây dựng một mạng phân lớp ảnhAnd now that you have an idea of convolutional neural network that you can build for image classification, ta có thể lấy tập dữ liệu cho việc phân loại: bộ dữ liệu MNIST, viết tắt của Modified National Institute of Standards and Technology database. Nó là một cơ sở dữ liệu lớn các số viết tay mà thường được sử dụng để luyện các hệ thống xử lý ảnh khác nhau.\n",
    "\n",
    "## 1.3. Tải về dữ liệu Mnist\n",
    "Bộ dữ liệu MNIST là một trong các bộ dữ liệu chung nhất được sử dụng cho việc phân lớp ảnh và có thể nhận được từ nhiều nguồn khác nhau. Trong thực tế, thậm chí Tensorflow và Keras cho phép chúng ta nhập và tải về bộ dữ liệu MNIST trực tiếp từ API của chúng. Do đó, ta sẽ bắt đầu với 2 dòng sau để import tensorflow và bộ dữ liệu MNIST dưới API của Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bộ dữ liệu MNIST chứa 60,000 ảnh luyện và 10,000 ảnh kiểm định lấy từ nhân viên cục điều tra dân số Mỹ và sinh viên trung học Mỹ. Do đó, trong dòng thứ 2, ta đã phân tách 2 nhóm dữ liệu luyện và dữ liệu kiểm định và cũng phân tách nhãn và ảnh. Các phần x_train và x_test chứa mã độ xám (từ 0 tới 255) trong khi các phần y_train và y_test chứa các nhãn từ 0 tới 9 mà thể hiện số mà ảnh thể hiện. Để trực quan hóa các số này, ta dùng tới thư viện matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26c9d7fa4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "image_index = 301 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta cũng cần biết và kích thước của bộ dữ liệu để chuyển nó tới mạng nơron tích chập. Do đó, ta sẽ sử dụng thuộc tính “shape” của mảng numpy với mã sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ nhận được (60000, 28, 28). Như ta có thể thấy 60000 thể hiện số ảnh trong bộ dữ liệu luyện và (28, 28) thể hiện kích thước của ảnh: 28 x 28 pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Định dạng lại và chuẩn hóa ảnh\n",
    "Để có thể sử dụng bộ dữ liệu từ API của Kerá, ta cần mảng numpy 4-chiều. Tuy nhiên, như ta đã thấy ở trên, mảng của chúng ta làm mảng 3-chiều. Thêm nữa, ta phải chuẩn hóa dữ liệu của ta như nó thường được đòi hỏi ở các mô hình mạng nơron. Ta có thể có được điều này bằng cách chia mã xãm cho 255 (mà là giá trị lớn nhất trừ đi giá trị nhỏ nhất. Xem đoạn mã sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Xây dựng mạng nơron tích chập\n",
    "Ta sẽ xây dựng mô hình bằng cách sử dụng API mức cao của Keras mà có thể sử dụng TensorFlow hay Theano như backend. Để ý rằng có một vài API mức cao của TensorFlow như Layers, Keras, và Estimators mà giúp ta tạo mạng nơron với tri thức mức cao. Do đó, ta có thể thấy các mã rất khác nhau của cùng một mạng nơron sử dụng tensorflow. Ta sẽ sử dụng trực tiếp các API của Keras. Do đó ta import Sequential Model from Keras và bổ sung các lớp Conv2D, MaxPooling, Flatten, Dropout, và Dense. Ta đã biết về các lớp Conv2D, Maxpooling, và Dense. Thêm vào đó, lớp Dropout loại bỏ overfitting bằng cách lờ đi một số nơron trong khi luyện. Lớp Flatten phẳng hóa mảng 2 chiều thành mảng 1 chiều trước khi xây dựng mạng kết nối đầy đủ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\training\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(60, kernel_size(3,3))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thử với một số nào đó đối với lớp Dense đầu; tuy nhiên lớp Dense sau phải có 10 nơron do ta có 10 lớp (0, 1, 2, …, 9). Ta có thể thử với kernel size, pool size, activation functions, dropout rate, và số nơron ở lớp Dense đầu để nhận kết quả tốt hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Dịch và luyện mô hình\n",
    "Vớ mã ở trên, ta đã tạo một mạng CNN rỗng, chưa tối ưu. Đây là lúc thiết lập bộ tối ưu với hàm mất mát và sử dụng một số đo. Sau đó ta có thể luywwnj mô hình sử dụng dữ liệu luyện của ta. Chúng ta sẽ sử dụng mã sau cho các công việc này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 0.2032 - accuracy: 0.9391\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 44s 736us/step - loss: 0.0837 - accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 44s 737us/step - loss: 0.0576 - accuracy: 0.9817\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 45s 751us/step - loss: 0.0441 - accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 45s 742us/step - loss: 0.0353 - accuracy: 0.9882\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 0.0283 - accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 43s 708us/step - loss: 0.0243 - accuracy: 0.9918\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 41s 686us/step - loss: 0.0228 - accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 0.0179 - accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 45s 747us/step - loss: 0.0170 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26c9d831c18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thử với optimizer, loss function, metrics, và epochs. Tuy nhiên, ta có thể nói rằng bộ tối ưu adam thường tốt hơn các bộ tối ưu khác. Ở đây số epoch có vẻ hơi nhỏ. Tuy nhiên ta sẽ tiến tới độ chính xác kiểm định là 98–99%. Do bộ dữ liệu MNIST không yêu cầu năng lực tính toán nhiều, ta có thể dễ dàng thử với số epoch lớn hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Đánh giá mô hình\n",
    "Cuối cùng, ta có thể đánh giá mô hình đã được luyện với x_test và y_test sử dụng 1 dòng mã:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 151us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06268354122400488, 0.9843999743461609]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta đã đạt được độ chính xác 98.5% với một mô hình cơ bản như vậy. Thành thật mà nói, trong nhiều trường hợp phân lớp ảnh (thí dụ với ô tô tự lái), ta thậm chí không thể chấp nhận lỗi 0.1% do nó sẽ gây ra 1 tai nạn trong số 1000 trường hợp. Tuy nhiên, đối với mô hình của ta, ta có thể nói kết quả tương đối tốt. Ta cũng có thể thực hiện các phép dự đoán với mã sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4252\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(\"model-mnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Giải thích\n",
    "Sử dụng sparse categorical crossentropy khi các lớp của ta loại trừ lẫn nhau (thí dụ mỗi mẫu thuộc về chính xác 1 lớp) và  categorical crossentropy khi một mẫu có thể có nhiều lớp hay nhãn là xác suất mềm (như [0.5, 0.3, 0.2]).\n",
    "<img src='files/crossentropy.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
